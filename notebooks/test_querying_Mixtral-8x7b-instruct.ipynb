{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Querying Mixtral-8x7b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# Add src module to path before import.\n",
    "sys.path.insert(0, str(pathlib.Path('../src')))\n",
    "\n",
    "from file_IO_handler import get_plaintext_file_contents\n",
    "from fill_string_template import get_filled_strings_from_dataframe, FilledString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Access to Replicate\n",
    "\n",
    "We will use Replicate hosted cloud environment.  \n",
    "Obtain Replicate API key â†’ https://replicate.com/account/api-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLICATE_API_KEY = get_plaintext_file_contents(pathlib.Path(\"../REPLICATE_API_KEY.env\"))\n",
    "# print(REPLICATE_API_KEY)\n",
    "\n",
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_KEY\n",
    "\n",
    "# use model hosted on Replicate server for inferencing\n",
    "model = \"mistralai/mixtral-8x7b-instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use replicate's hosted api\n",
    "import replicate\n",
    "\n",
    "# text completion with input prompt\n",
    "def Completion(prompt):\n",
    "  output = replicate.run(\n",
    "      model,\n",
    "      input={\"prompt\": prompt, \"max_new_tokens\":1000}\n",
    "  )\n",
    "  return \"\".join(output)\n",
    "\n",
    "# chat completion with input prompt and system prompt\n",
    "def ChatCompletion(prompt, system_prompt=None):\n",
    "  output = replicate.run(\n",
    "    model,\n",
    "    input={\"system_prompt\": system_prompt,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_new_tokens\":1000}\n",
    "  )\n",
    "  return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Completion(prompt=\"The typical color of a llama is: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for your kind words! I\\'m here to help you.\\n\\nLlamas are fascinating animals, and their coat color can vary widely. The most common color of a llama is a light brown or tan, but they can also be black, white, gray, or even multi-colored. Some llamas have a pattern called \"appaloosa,\" which features spots of different colors on a white or light-colored background. So while light brown or tan is the most typical color, there is a lot of variation within the species!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ChatCompletion(\n",
    "    prompt=\"The typical color of a llama is: \",\n",
    "    system_prompt=\"response in json format\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"response\": {\\n    \"answer\": \"brown\",\\n    \"explanation\": \"While llamas can come in a variety of colors, the most common color is brown.\"\\n  }\\n}\\n\\nLlamas are often associated with the image of a brown animal, although they can also be found in other colors such as white, black, and gray. The exact shade of brown can vary, with some llamas being a light tan and others being a deep chocolate brown.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama_2_metaphor_generation_with_LLMs]",
   "language": "python",
   "name": "conda-env-llama_2_metaphor_generation_with_LLMs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
