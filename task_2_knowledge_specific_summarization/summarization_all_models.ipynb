{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd808bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import replicate\n",
    "import pickle\n",
    "from rouge import Rouge\n",
    "from wikipedia import wikipedia\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f117e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"REPLICATE_API_TOKEN\"] = # YOUR REPLICATE API KEY HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_wikipedia_articles(keyword, num_articles=1):\n",
    "    articles = []\n",
    "    search_results = wikipedia.search(keyword, num_articles)\n",
    "    for result in search_results:\n",
    "        try:\n",
    "            page = wikipedia.page(result)\n",
    "            articles.append(page.content)\n",
    "        except:\n",
    "            print(f\"No Wikipedia page found for '{result}'.\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_prompt(llm_keywords):\n",
    "    related_articles = retrieve_wikipedia_articles(llm_keywords)\n",
    "    rag_prompt = \" \".join(article for article in related_articles)\n",
    "    return rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(hypotheses, references):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to download the USB benchmark for the test.jsonl file\n",
    "test = pd.read_json(path_or_buf='usb/task_datasets/all/abstractive_summarization/test.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f635a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for i in range(test.shape[0]):\n",
    "    x, y = \" \".join(test['input_lines'][i])[:4096], \" \".join(test['output_lines'][i])\n",
    "    xs.append(x)\n",
    "    ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [xs[i].split('.')[0] for i in range(len(xs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88db168",
   "metadata": {},
   "source": [
    "###  Summarization GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ecc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a37348",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptkey = # YOUR OPENAI API KEY HERE\n",
    "client = OpenAI(api_key=gptkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_outputs = []\n",
    "for i,x in tqdm(enumerate(xs)):\n",
    "    topic = topics[i]\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Summarize the following passage about {topic} in a few sentences: {x}\"}]\n",
    "            )\n",
    "    output = response.choices[0].message.content\n",
    "    gpt_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(gpt_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d1f3a",
   "metadata": {},
   "source": [
    "### Summarization  Llama-2-70b-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_outputs = []\n",
    "for i, x in tqdm(enumerate(xs)):\n",
    "    topic = topics[i]\n",
    "    output = replicate.run(\n",
    "    \"meta/llama-2-70b-chat\",\n",
    "    input={\n",
    "        \"top_k\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"prompt\": x,\n",
    "        \"temperature\": 0.75,\n",
    "        \"system_prompt\": f\"Summarize the following passage about {topic} in a few sentences\",\n",
    "        \"length_penalty\": 1,\n",
    "        \"max_new_tokens\": 800,\n",
    "        \"prompt_template\": \"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{prompt} [/INST]\",\n",
    "        \"presence_penalty\": 0\n",
    "        }\n",
    "    )\n",
    "    output = \"\".join(output)\n",
    "    llama_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llama_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(llama_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c482a6",
   "metadata": {},
   "source": [
    "### Summarization Mixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e144cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral_outputs = []\n",
    "for i,x in tqdm(enumerate(xs)):\n",
    "    topic = topics[i]\n",
    "    output = replicate.run(\n",
    "    \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
    "    input={\n",
    "        \"top_k\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"prompt\": x,\n",
    "        \"temperature\": 0.75,\n",
    "        \"system_prompt\": f\"Summarize the following passage about {topic} in a few sentences\",\n",
    "        \"length_penalty\": 1,\n",
    "        \"max_new_tokens\": 800,\n",
    "        \"prompt_template\": \"<s>[INST] {prompt} [/INST] \",\n",
    "        \"presence_penalty\": 0\n",
    "        }\n",
    "    )\n",
    "    output = \"\".join(output)\n",
    "    mixtral_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381729bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mixtral_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(mixtral_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6c663",
   "metadata": {},
   "source": [
    "### Calculate ROUGE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_scores, llama_scores, mixtral_scores = [], [], []\n",
    "for i, y in enumerate(ys):\n",
    "    gpt_scores.append(calculate_rouge_scores(gpt_outputs[i], y)['rouge-l']['r'])\n",
    "    llama_scores.append(calculate_rouge_scores(llama_outputs[i], y)['rouge-l']['r'])\n",
    "    mixtral_scores.append(calculate_rouge_scores(mixtral_outputs[i], y)['rouge-l']['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(gpt_scores), np.mean(llama_scores), np.mean(mixtral_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bff7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(gpt_scores), np.std(llama_scores), np.std(mixtral_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13378329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
